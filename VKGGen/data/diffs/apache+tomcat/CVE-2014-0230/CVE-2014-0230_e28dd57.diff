commit e28dd578fad90a6d5726ec34f3245c9f99d909a5
Author:     Mark Emlyn David Thomas <markt@apache.org>
AuthorDate: Thu Jun 19 09:06:39 2014 +0000
Commit:     Mark Emlyn David Thomas <markt@apache.org>
CommitDate: Thu Jun 19 09:06:39 2014 +0000

    Add a new limit, defaulting to 2MB, for the amount of data Tomcat will swallow for an aborted upload.
    
    git-svn-id: https://svn.apache.org/repos/asf/tomcat/trunk@1603770 13f79535-47bb-0310-9956-ffa450edef68

diff --git a/java/org/apache/coyote/http11/AbstractHttp11Processor.java b/java/org/apache/coyote/http11/AbstractHttp11Processor.java
index 1430ceae8d..b22349ffcd 100644
--- a/java/org/apache/coyote/http11/AbstractHttp11Processor.java
+++ b/java/org/apache/coyote/http11/AbstractHttp11Processor.java
@@ -647,14 +647,15 @@ public abstract class AbstractHttp11Processor<S> extends AbstractProcessor<S> {
     /**
      * Initialize standard input and output filters.
      */
-    protected void initializeFilters(int maxTrailerSize, int maxExtensionSize) {
+    protected void initializeFilters(int maxTrailerSize, int maxExtensionSize,
+            int maxSwallowSize) {
         // Create and add the identity filters.
-        getInputBuffer().addFilter(new IdentityInputFilter());
+        getInputBuffer().addFilter(new IdentityInputFilter(maxSwallowSize));
         getOutputBuffer().addFilter(new IdentityOutputFilter());
 
         // Create and add the chunked filters.
         getInputBuffer().addFilter(
-                new ChunkedInputFilter(maxTrailerSize, maxExtensionSize));
+                new ChunkedInputFilter(maxTrailerSize, maxExtensionSize, maxSwallowSize));
         getOutputBuffer().addFilter(new ChunkedOutputFilter());
 
         // Create and add the void filters.
diff --git a/java/org/apache/coyote/http11/AbstractHttp11Protocol.java b/java/org/apache/coyote/http11/AbstractHttp11Protocol.java
index a31091cd9f..3be34741e6 100644
--- a/java/org/apache/coyote/http11/AbstractHttp11Protocol.java
+++ b/java/org/apache/coyote/http11/AbstractHttp11Protocol.java
@@ -154,6 +154,16 @@ public abstract class AbstractHttp11Protocol<S> extends AbstractProtocol<S> {
     }
 
 
+    /**
+     * Maximum amount of request body to swallow.
+     */
+    private int maxSwallowSize = 2 * 1024 * 1024;
+    public int getMaxSwallowSize() { return maxSwallowSize; }
+    public void setMaxSwallowSize(int maxSwallowSize) {
+        this.maxSwallowSize = maxSwallowSize;
+    }
+
+
     /**
      * This field indicates if the protocol is treated as if it is secure. This
      * normally means https is being used but can be used to fake https e.g
diff --git a/java/org/apache/coyote/http11/Http11AprProcessor.java b/java/org/apache/coyote/http11/Http11AprProcessor.java
index 08a7f27cac..e4ecd1a370 100644
--- a/java/org/apache/coyote/http11/Http11AprProcessor.java
+++ b/java/org/apache/coyote/http11/Http11AprProcessor.java
@@ -59,7 +59,7 @@ public class Http11AprProcessor extends AbstractHttp11Processor<Long> {
 
 
     public Http11AprProcessor(int headerBufferSize, AprEndpoint endpoint,
-            int maxTrailerSize, int maxExtensionSize) {
+            int maxTrailerSize, int maxExtensionSize, int maxSwallowSize) {
 
         super(endpoint);
 
@@ -69,7 +69,7 @@ public class Http11AprProcessor extends AbstractHttp11Processor<Long> {
         outputBuffer = new InternalAprOutputBuffer(response, headerBufferSize);
         response.setOutputBuffer(outputBuffer);
 
-        initializeFilters(maxTrailerSize, maxExtensionSize);
+        initializeFilters(maxTrailerSize, maxExtensionSize, maxSwallowSize);
     }
 
 
diff --git a/java/org/apache/coyote/http11/Http11AprProtocol.java b/java/org/apache/coyote/http11/Http11AprProtocol.java
index 024e93dbae..d32b0073f9 100644
--- a/java/org/apache/coyote/http11/Http11AprProtocol.java
+++ b/java/org/apache/coyote/http11/Http11AprProtocol.java
@@ -319,7 +319,8 @@ public class Http11AprProtocol extends AbstractHttp11Protocol<Long> {
         protected Http11AprProcessor createProcessor() {
             Http11AprProcessor processor = new Http11AprProcessor(
                     proto.getMaxHttpHeaderSize(), (AprEndpoint)proto.endpoint,
-                    proto.getMaxTrailerSize(), proto.getMaxExtensionSize());
+                    proto.getMaxTrailerSize(), proto.getMaxExtensionSize(),
+                    proto.getMaxSwallowSize());
             processor.setAdapter(proto.getAdapter());
             processor.setMaxKeepAliveRequests(proto.getMaxKeepAliveRequests());
             processor.setKeepAliveTimeout(proto.getKeepAliveTimeout());
diff --git a/java/org/apache/coyote/http11/Http11Nio2Processor.java b/java/org/apache/coyote/http11/Http11Nio2Processor.java
index d9ea12fc4c..c57c87e3e2 100644
--- a/java/org/apache/coyote/http11/Http11Nio2Processor.java
+++ b/java/org/apache/coyote/http11/Http11Nio2Processor.java
@@ -60,7 +60,7 @@ public class Http11Nio2Processor extends AbstractHttp11Processor<Nio2Channel> {
 
 
     public Http11Nio2Processor(int maxHttpHeaderSize, Nio2Endpoint endpoint,
-            int maxTrailerSize, int maxExtensionSize) {
+            int maxTrailerSize, int maxExtensionSize, int maxSwallowSize) {
 
         super(endpoint);
 
@@ -70,7 +70,7 @@ public class Http11Nio2Processor extends AbstractHttp11Processor<Nio2Channel> {
         outputBuffer = new InternalNio2OutputBuffer(response, maxHttpHeaderSize);
         response.setOutputBuffer(outputBuffer);
 
-        initializeFilters(maxTrailerSize, maxExtensionSize);
+        initializeFilters(maxTrailerSize, maxExtensionSize, maxSwallowSize);
     }
 
 
diff --git a/java/org/apache/coyote/http11/Http11Nio2Protocol.java b/java/org/apache/coyote/http11/Http11Nio2Protocol.java
index 94465581f0..3e02a8d164 100644
--- a/java/org/apache/coyote/http11/Http11Nio2Protocol.java
+++ b/java/org/apache/coyote/http11/Http11Nio2Protocol.java
@@ -248,7 +248,8 @@ public class Http11Nio2Protocol extends AbstractHttp11JsseProtocol<Nio2Channel>
         public Http11Nio2Processor createProcessor() {
             Http11Nio2Processor processor = new Http11Nio2Processor(
                     proto.getMaxHttpHeaderSize(), (Nio2Endpoint) proto.endpoint,
-                    proto.getMaxTrailerSize(), proto.getMaxExtensionSize());
+                    proto.getMaxTrailerSize(), proto.getMaxExtensionSize(),
+                    proto.getMaxSwallowSize());
             processor.setAdapter(proto.getAdapter());
             processor.setMaxKeepAliveRequests(proto.getMaxKeepAliveRequests());
             processor.setKeepAliveTimeout(proto.getKeepAliveTimeout());
diff --git a/java/org/apache/coyote/http11/Http11NioProcessor.java b/java/org/apache/coyote/http11/Http11NioProcessor.java
index c8d319c258..30aa9e9697 100644
--- a/java/org/apache/coyote/http11/Http11NioProcessor.java
+++ b/java/org/apache/coyote/http11/Http11NioProcessor.java
@@ -63,7 +63,7 @@ public class Http11NioProcessor extends AbstractHttp11Processor<NioChannel> {
 
 
     public Http11NioProcessor(int maxHttpHeaderSize, NioEndpoint endpoint,
-            int maxTrailerSize, int maxExtensionSize) {
+            int maxTrailerSize, int maxExtensionSize, int maxSwallowSize) {
 
         super(endpoint);
 
@@ -73,7 +73,7 @@ public class Http11NioProcessor extends AbstractHttp11Processor<NioChannel> {
         outputBuffer = new InternalNioOutputBuffer(response, maxHttpHeaderSize);
         response.setOutputBuffer(outputBuffer);
 
-        initializeFilters(maxTrailerSize, maxExtensionSize);
+        initializeFilters(maxTrailerSize, maxExtensionSize, maxSwallowSize);
     }
 
 
diff --git a/java/org/apache/coyote/http11/Http11NioProtocol.java b/java/org/apache/coyote/http11/Http11NioProtocol.java
index 77646d75ec..585f44943f 100644
--- a/java/org/apache/coyote/http11/Http11NioProtocol.java
+++ b/java/org/apache/coyote/http11/Http11NioProtocol.java
@@ -280,7 +280,8 @@ public class Http11NioProtocol extends AbstractHttp11JsseProtocol<NioChannel> {
         public Http11NioProcessor createProcessor() {
             Http11NioProcessor processor = new Http11NioProcessor(
                     proto.getMaxHttpHeaderSize(), (NioEndpoint)proto.endpoint,
-                    proto.getMaxTrailerSize(), proto.getMaxExtensionSize());
+                    proto.getMaxTrailerSize(), proto.getMaxExtensionSize(),
+                    proto.getMaxSwallowSize());
             processor.setAdapter(proto.getAdapter());
             processor.setMaxKeepAliveRequests(proto.getMaxKeepAliveRequests());
             processor.setKeepAliveTimeout(proto.getKeepAliveTimeout());
diff --git a/java/org/apache/coyote/http11/Http11Processor.java b/java/org/apache/coyote/http11/Http11Processor.java
index ad58b78a2d..98f8dbad16 100644
--- a/java/org/apache/coyote/http11/Http11Processor.java
+++ b/java/org/apache/coyote/http11/Http11Processor.java
@@ -49,7 +49,7 @@ public class Http11Processor extends AbstractHttp11Processor<Socket> {
 
 
     public Http11Processor(int headerBufferSize, JIoEndpoint endpoint,
-            int maxTrailerSize, int maxExtensionSize) {
+            int maxTrailerSize, int maxExtensionSize, int maxSwallowSize) {
 
         super(endpoint);
 
@@ -59,7 +59,7 @@ public class Http11Processor extends AbstractHttp11Processor<Socket> {
         outputBuffer = new InternalOutputBuffer(response, headerBufferSize);
         response.setOutputBuffer(outputBuffer);
 
-        initializeFilters(maxTrailerSize, maxExtensionSize);
+        initializeFilters(maxTrailerSize, maxExtensionSize, maxSwallowSize);
     }
 
 
diff --git a/java/org/apache/coyote/http11/Http11Protocol.java b/java/org/apache/coyote/http11/Http11Protocol.java
index 81e8fa3fab..8f13aced69 100644
--- a/java/org/apache/coyote/http11/Http11Protocol.java
+++ b/java/org/apache/coyote/http11/Http11Protocol.java
@@ -186,7 +186,8 @@ public class Http11Protocol extends AbstractHttp11JsseProtocol<Socket> {
         protected Http11Processor createProcessor() {
             Http11Processor processor = new Http11Processor(
                     proto.getMaxHttpHeaderSize(), (JIoEndpoint)proto.endpoint,
-                    proto.getMaxTrailerSize(),proto.getMaxExtensionSize());
+                    proto.getMaxTrailerSize(),proto.getMaxExtensionSize(),
+                    proto.getMaxSwallowSize());
             processor.setAdapter(proto.getAdapter());
             processor.setMaxKeepAliveRequests(proto.getMaxKeepAliveRequests());
             processor.setKeepAliveTimeout(proto.getKeepAliveTimeout());
diff --git a/java/org/apache/coyote/http11/filters/ChunkedInputFilter.java b/java/org/apache/coyote/http11/filters/ChunkedInputFilter.java
index f3315b58b7..e64aadb437 100644
--- a/java/org/apache/coyote/http11/filters/ChunkedInputFilter.java
+++ b/java/org/apache/coyote/http11/filters/ChunkedInputFilter.java
@@ -137,6 +137,9 @@ public class ChunkedInputFilter implements InputFilter {
     private long extensionSize;
 
 
+    private final int maxSwallowSize;
+
+
     /**
      * Flag that indicates if an error has occurred.
      */
@@ -145,10 +148,11 @@ public class ChunkedInputFilter implements InputFilter {
 
     // ----------------------------------------------------------- Constructors
 
-    public ChunkedInputFilter(int maxTrailerSize, int maxExtensionSize) {
+    public ChunkedInputFilter(int maxTrailerSize, int maxExtensionSize, int maxSwallowSize) {
         this.trailingHeaders.setLimit(maxTrailerSize);
         this.maxExtensionSize = maxExtensionSize;
         this.maxTrailerSize = maxTrailerSize;
+        this.maxSwallowSize = maxSwallowSize;
     }
 
 
@@ -234,9 +238,14 @@ public class ChunkedInputFilter implements InputFilter {
      */
     @Override
     public long end() throws IOException {
+        long swallowed = 0;
+        int read = 0;
         // Consume extra bytes : parse the stream until the end chunk is found
-        while (doRead(readChunk, null) >= 0) {
-            // NOOP: Just consume the input
+        while ((read = doRead(readChunk, null)) >= 0) {
+            swallowed += read;
+            if (maxSwallowSize > -1 && swallowed > maxSwallowSize) {
+                throwIOException(sm.getString("inputFilter.maxSwallow"));
+            }
         }
 
         // Return the number of extra bytes which were consumed
diff --git a/java/org/apache/coyote/http11/filters/IdentityInputFilter.java b/java/org/apache/coyote/http11/filters/IdentityInputFilter.java
index 35846177b8..c1e45bfd31 100644
--- a/java/org/apache/coyote/http11/filters/IdentityInputFilter.java
+++ b/java/org/apache/coyote/http11/filters/IdentityInputFilter.java
@@ -24,6 +24,7 @@ import org.apache.coyote.InputBuffer;
 import org.apache.coyote.Request;
 import org.apache.coyote.http11.InputFilter;
 import org.apache.tomcat.util.buf.ByteChunk;
+import org.apache.tomcat.util.res.StringManager;
 
 /**
  * Identity input filter.
@@ -32,6 +33,9 @@ import org.apache.tomcat.util.buf.ByteChunk;
  */
 public class IdentityInputFilter implements InputFilter {
 
+    private static final StringManager sm = StringManager.getManager(
+            IdentityInputFilter.class.getPackage().getName());
+
 
     // -------------------------------------------------------------- Constants
 
@@ -76,6 +80,14 @@ public class IdentityInputFilter implements InputFilter {
     protected final ByteChunk endChunk = new ByteChunk();
 
 
+    private final int maxSwallowSize;
+
+
+    public IdentityInputFilter(int maxSwallowSize) {
+        this.maxSwallowSize = maxSwallowSize;
+    }
+
+
     // ---------------------------------------------------- InputBuffer Methods
 
     /**
@@ -137,8 +149,11 @@ public class IdentityInputFilter implements InputFilter {
      * End the current request.
      */
     @Override
-    public long end()
-        throws IOException {
+    public long end()  throws IOException {
+
+        if (maxSwallowSize > -1 && remaining > maxSwallowSize) {
+            throw new IOException(sm.getString("inputFilter.maxSwallow"));
+        }
 
         // Consume extra bytes.
         while (remaining > 0) {
diff --git a/java/org/apache/coyote/http11/filters/LocalStrings.properties b/java/org/apache/coyote/http11/filters/LocalStrings.properties
index b4723657f5..0542fb5f5e 100644
--- a/java/org/apache/coyote/http11/filters/LocalStrings.properties
+++ b/java/org/apache/coyote/http11/filters/LocalStrings.properties
@@ -22,4 +22,6 @@ chunkedInputFilter.invalidCrlfNoCR=Invalid end of line sequence (No CR before LF
 chunkedInputFilter.invalidCrlfNoData=Invalid end of line sequence (no data available to read)
 chunkedInputFilter.invalidHeader=Invalid chunk header
 chunkedInputFilter.maxExtension=maxExtensionSize exceeded
-chunkedInputFilter.maxTrailer=maxTrailerSize exceeded
\ No newline at end of file
+chunkedInputFilter.maxTrailer=maxTrailerSize exceeded
+
+inputFilter.maxSwallow=maxSwallowSize exceeded
\ No newline at end of file
diff --git a/test/org/apache/catalina/core/TestSwallowAbortedUploads.java b/test/org/apache/catalina/core/TestSwallowAbortedUploads.java
index d97289cc46..f08f3d765a 100644
--- a/test/org/apache/catalina/core/TestSwallowAbortedUploads.java
+++ b/test/org/apache/catalina/core/TestSwallowAbortedUploads.java
@@ -16,8 +16,14 @@
  */
 package org.apache.catalina.core;
 
+import java.io.BufferedReader;
 import java.io.IOException;
+import java.io.InputStreamReader;
+import java.io.OutputStreamWriter;
 import java.io.PrintWriter;
+import java.io.Writer;
+import java.net.Socket;
+import java.nio.charset.StandardCharsets;
 import java.util.Arrays;
 import java.util.Collection;
 
@@ -32,6 +38,7 @@ import javax.servlet.http.Part;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 
+import org.junit.Assert;
 import org.junit.Test;
 
 import org.apache.catalina.Context;
@@ -113,7 +120,7 @@ public class TestSwallowAbortedUploads extends TomcatBaseTest {
         Exception ex = doAbortedUploadTest(client, true, true);
         assertNull("Limited upload with swallow enabled generates client exception",
                    ex);
-        assertTrue("Limited upload with swallow enabled returns error status code",
+        assertTrue("Limited upload with swallow enabled returns non-500 status code",
                    client.isResponse500());
         client.reset();
     }
@@ -400,4 +407,72 @@ public class TestSwallowAbortedUploads extends TomcatBaseTest {
         }
     }
 
+
+    @Test
+    public void testChunkedPUTLimit() throws Exception {
+        doTestChunkedPUT(true);
+    }
+
+
+    @Test
+    public void testChunkedPUTNoLimit() throws Exception {
+        doTestChunkedPUT(false);
+    }
+
+
+    public void doTestChunkedPUT(boolean limit) throws Exception {
+
+        Tomcat tomcat = getTomcatInstance();
+        tomcat.addContext("", TEMP_DIR);
+        // No need for target to exist.
+
+        if (!limit) {
+            tomcat.getConnector().setAttribute("maxSwallowSize", "-1");
+        }
+
+        tomcat.start();
+
+        Exception writeEx = null;
+        Exception readEx = null;
+        String responseLine = null;
+
+        try (Socket conn = new Socket("localhost", getPort())) {
+            Writer writer = new OutputStreamWriter(
+                    conn.getOutputStream(), StandardCharsets.US_ASCII);
+            writer.write("PUT /does-not-exist HTTP/1.1\r\n");
+            writer.write("Host: any\r\n");
+            writer.write("Transfer-encoding: chunked\r\n");
+            writer.write("\r\n");
+
+            // Smarter than the typical client. Attempts to read the response
+            // even if the request is not fully written.
+            try {
+                // Write (or try to write) 16MB
+                for (int i = 0; i < 1024 * 1024; i++) {
+                    writer.write("10\r\n");
+                    writer.write("0123456789ABCDEF\r\n");
+                }
+            } catch (Exception e) {
+                writeEx = e;
+            }
+
+            try {
+                BufferedReader reader = new BufferedReader(new InputStreamReader(
+                        conn.getInputStream(), StandardCharsets.US_ASCII));
+
+                responseLine = reader.readLine();
+            } catch (IOException e) {
+                readEx = e;
+            }
+        }
+
+        if (limit) {
+            Assert.assertNotNull(writeEx);
+        } else {
+            Assert.assertNull(writeEx);
+        }
+        Assert.assertNull(readEx);
+        Assert.assertNotNull(responseLine);
+        Assert.assertTrue(responseLine.contains("404"));
+    }
 }
diff --git a/webapps/docs/changelog.xml b/webapps/docs/changelog.xml
index 68ecf9d734..d6748e031f 100644
--- a/webapps/docs/changelog.xml
+++ b/webapps/docs/changelog.xml
@@ -205,6 +205,10 @@
       <fix>
         Improve configuration of cache sizes in the endpoint. (markt)
       </fix>
+      <add>
+        Add a new limit, defaulting to 2MB, for the amount of data Tomcat will
+        swallow for an aborted upload. (markt)
+      </add>
     </changelog>
   </subsection>
   <subsection name="Jasper">
diff --git a/webapps/docs/config/http.xml b/webapps/docs/config/http.xml
index f29eda16fa..709b6b0dd0 100644
--- a/webapps/docs/config/http.xml
+++ b/webapps/docs/config/http.xml
@@ -436,6 +436,16 @@
       If not specified, this attribute is set to 100.</p>
     </attribute>
 
+    <attribute name="maxSwallowSize" required="false">
+      <p>The maximum number of request body bytes (excluding transfer encoding
+      overhead) that will be swallowed by Tomcat for an aborted upload. An
+      aborted upload is when Tomcat knows that the request body is going to be
+      ignored but the client still sends it. If Tomcat does not swallow the body
+      the client is unlikely to see the response. If not specified the default
+      of 2097152 (2 megabytes) will be used. A value of less than zero indicates
+      that no limit should be enforced.</p>
+    </attribute>
+
     <attribute name="maxThreads" required="false">
       <p>The maximum number of request processing threads to be created
       by this <strong>Connector</strong>, which therefore determines the
