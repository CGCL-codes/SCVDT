static void cleanup_net(struct work_struct *work)
{
	struct pernet_operations *ops;
	struct net *net, *tmp;
	LIST_HEAD(net_kill_list);

	/* Atomically snapshot the list of namespaces to cleanup */
	spin_lock_irq(&cleanup_list_lock);
	list_replace_init(&cleanup_list, &net_kill_list);
	spin_unlock_irq(&cleanup_list_lock);

	mutex_lock(&net_mutex);

	/* Don't let anyone else find us. */
	rtnl_lock();
	list_for_each_entry(net, &net_kill_list, cleanup_list)
		list_del_rcu(&net->list);
	rtnl_unlock();

	/*
	 * Another CPU might be rcu-iterating the list, wait for it.
	 * This needs to be before calling the exit() notifiers, so
	 * the rcu_barrier() below isn't sufficient alone.
	 */
	synchronize_rcu();

	/* Run all of the network namespace exit methods */
	list_for_each_entry_reverse(ops, &pernet_list, list) {
		if (ops->exit) {
			list_for_each_entry(net, &net_kill_list, cleanup_list)
				ops->exit(net);
		}
		if (&ops->list == first_device) {
			LIST_HEAD(dev_kill_list);
			rtnl_lock();
			list_for_each_entry(net, &net_kill_list, cleanup_list)
				unregister_netdevices(net, &dev_kill_list);
			unregister_netdevice_many(&dev_kill_list);
			rtnl_unlock();
		}
	}

	mutex_unlock(&net_mutex);

	/* Ensure there are no outstanding rcu callbacks using this
	 * network namespace.
	 */
	rcu_barrier();

	/* Finally it is safe to free my network namespace structure */
	list_for_each_entry_safe(net, tmp, &net_kill_list, cleanup_list) {
		list_del_init(&net->cleanup_list);
		net_free(net);
	}
}
