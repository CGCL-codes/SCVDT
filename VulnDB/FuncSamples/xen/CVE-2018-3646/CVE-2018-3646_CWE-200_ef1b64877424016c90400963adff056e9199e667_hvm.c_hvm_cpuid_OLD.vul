void hvm_cpuid(unsigned int input, unsigned int *eax, unsigned int *ebx,
                                   unsigned int *ecx, unsigned int *edx)
{
    struct vcpu *v = current;
    struct domain *d = v->domain;
    unsigned int count, dummy = 0;

    if ( !eax )
        eax = &dummy;
    if ( !ebx )
        ebx = &dummy;
    if ( !ecx )
        ecx = &dummy;
    count = *ecx;
    if ( !edx )
        edx = &dummy;

    if ( cpuid_viridian_leaves(input, eax, ebx, ecx, edx) )
        return;

    if ( cpuid_hypervisor_leaves(input, count, eax, ebx, ecx, edx) )
        return;

    domain_cpuid(d, input, count, eax, ebx, ecx, edx);

    switch ( input )
    {
        unsigned int sub_leaf, _eax, _ebx, _ecx, _edx;

    case 0x1:
        /* Fix up VLAPIC details. */
        *ebx &= 0x00FFFFFFu;
        *ebx |= (v->vcpu_id * 2) << 24;
        if ( vlapic_hw_disabled(vcpu_vlapic(v)) )
            __clear_bit(X86_FEATURE_APIC & 31, edx);

        /* Fix up OSXSAVE. */
        if ( cpu_has_xsave )
            *ecx |= (v->arch.hvm_vcpu.guest_cr[4] & X86_CR4_OSXSAVE) ?
                     cpufeat_mask(X86_FEATURE_OSXSAVE) : 0;

        /* Don't expose PCID to non-hap hvm. */
        if ( !hap_enabled(d) )
            *ecx &= ~cpufeat_mask(X86_FEATURE_PCID);

        /* Only provide PSE36 when guest runs in 32bit PAE or in long mode */
        if ( !(hvm_pae_enabled(v) || hvm_long_mode_enabled(v)) )
            *edx &= ~cpufeat_mask(X86_FEATURE_PSE36);
        break;
    case 0x7:
        if ( (count == 0) && !cpu_has_smep )
            *ebx &= ~cpufeat_mask(X86_FEATURE_SMEP);

        if ( (count == 0) && !cpu_has_smap )
            *ebx &= ~cpufeat_mask(X86_FEATURE_SMAP);

        /* Don't expose MPX to hvm when VMX support is not available */
        if ( (count == 0) && !cpu_has_vmx_mpx )
            *ebx &= ~cpufeat_mask(X86_FEATURE_MPX);

        /* Don't expose INVPCID to non-hap hvm. */
        if ( (count == 0) && !hap_enabled(d) )
            *ebx &= ~cpufeat_mask(X86_FEATURE_INVPCID);

        if ( count == 0 )
        {
            if ( !boot_cpu_has(X86_FEATURE_SC_MSR_HVM) )
                *edx &= ~(cpufeat_mask(X86_FEATURE_IBRSB) |
                          cpufeat_mask(X86_FEATURE_SSBD));

            /*
             * Override STIBP to match IBRS.  Guests can safely use STIBP
             * functionality on non-HT hardware, but can't necesserily protect
             * themselves from SP2/Spectre/Branch Target Injection if STIBP is
             * hidden on HT-capable hardware.
             */
            if ( *edx & cpufeat_mask(X86_FEATURE_IBRSB) )
                *edx |= cpufeat_mask(X86_FEATURE_STIBP);
            else
                *edx &= ~cpufeat_mask(X86_FEATURE_STIBP);
        }
        break;
    case 0xb:
        /* Fix the x2APIC identifier. */
        *edx = v->vcpu_id * 2;
        break;
    case 0xd:
        /* EBX value of main leaf 0 depends on enabled xsave features */
        if ( count == 0 && v->arch.xcr0 ) 
        {
            /* reset EBX to default value first */
            *ebx = XSTATE_AREA_MIN_SIZE; 
            for ( sub_leaf = 2; sub_leaf < 63; sub_leaf++ )
            {
                if ( !(v->arch.xcr0 & (1ULL << sub_leaf)) )
                    continue;
                domain_cpuid(d, input, sub_leaf, &_eax, &_ebx, &_ecx, 
                             &_edx);
                if ( (_eax + _ebx) > *ebx )
                    *ebx = _eax + _ebx;
            }
        }
        break;

    case 0x80000001:
        /* We expose RDTSCP feature to guest only when
           tsc_mode == TSC_MODE_DEFAULT and host_tsc_is_safe() returns 1 */
        if ( d->arch.tsc_mode != TSC_MODE_DEFAULT ||
             !host_tsc_is_safe() )
            *edx &= ~cpufeat_mask(X86_FEATURE_RDTSCP);
        /* Hide 1GB-superpage feature if we can't emulate it. */
        if (!hvm_pse1gb_supported(d))
            *edx &= ~cpufeat_mask(X86_FEATURE_PAGE1GB);
        /* Only provide PSE36 when guest runs in 32bit PAE or in long mode */
        if ( !(hvm_pae_enabled(v) || hvm_long_mode_enabled(v)) )
            *edx &= ~cpufeat_mask(X86_FEATURE_PSE36);
        /* Hide data breakpoint extensions if the hardware has no support. */
        if ( !boot_cpu_has(X86_FEATURE_DBEXT) )
            *ecx &= ~cpufeat_mask(X86_FEATURE_DBEXT);
        break;

    case 0x80000008:
        count = d->arch.paging.gfn_bits + PAGE_SHIFT;
        if ( (*eax & 0xff) > count )
            *eax = (*eax & ~0xff) | count;

        hvm_cpuid(1, NULL, NULL, NULL, &_edx);
        count = _edx & (cpufeat_mask(X86_FEATURE_PAE) |
                        cpufeat_mask(X86_FEATURE_PSE36)) ? 36 : 32;
        if ( (*eax & 0xff) < count )
            *eax = (*eax & ~0xff) | count;

        hvm_cpuid(0x80000001, NULL, NULL, NULL, &_edx);
        *eax = (*eax & ~0xffff00) | (_edx & cpufeat_mask(X86_FEATURE_LM)
                                     ? 0x3000 : 0x2000);

        /* AMD's IBPB is a subset of IBRS/IBPB. */
        hvm_cpuid(7, NULL, &_ebx, NULL, NULL);
        if ( _ebx & cpufeat_mask(X86_FEATURE_IBRSB) )
            *ebx |= cpufeat_mask(X86_FEATURE_IBPB);
        break;
    }
}
