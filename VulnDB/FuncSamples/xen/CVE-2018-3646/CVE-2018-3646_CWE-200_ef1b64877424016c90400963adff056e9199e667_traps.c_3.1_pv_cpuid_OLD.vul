void pv_cpuid(struct cpu_user_regs *regs)
{
    uint32_t a, b, c, d;
    struct vcpu *curr = current;
    struct domain *currd = curr->domain;

    a = regs->eax;
    b = regs->ebx;
    c = regs->ecx;
    d = regs->edx;

    if ( !is_control_domain(currd) && !is_hardware_domain(currd) )
    {
        unsigned int cpuid_leaf = a, sub_leaf = c;

        if ( !cpuid_hypervisor_leaves(a, c, &a, &b, &c, &d) )
            domain_cpuid(currd, a, c, &a, &b, &c, &d);

        switch ( cpuid_leaf )
        {
            unsigned int _eax, _ebx, _ecx, _edx;

        case XSTATE_CPUID:
        {
            /* EBX value of main leaf 0 depends on enabled xsave features */
            if ( sub_leaf == 0 && curr->arch.xcr0 )
            {
                /* reset EBX to default value first */
                b = XSTATE_AREA_MIN_SIZE;
                for ( sub_leaf = 2; sub_leaf < 63; sub_leaf++ )
                {
                    if ( !(curr->arch.xcr0 & (1ULL << sub_leaf)) )
                        continue;
                    domain_cpuid(currd, cpuid_leaf, sub_leaf,
                                 &_eax, &_ebx, &_ecx, &_edx);
                    if ( (_eax + _ebx) > b )
                        b = _eax + _ebx;
                }
            }
            goto xstate;
        }

        case 0x00000007:
            if ( regs->_ecx == 0 )
            {
                if ( !boot_cpu_has(X86_FEATURE_SC_MSR_PV) )
                    d &= ~(cpufeat_mask(X86_FEATURE_IBRSB) |
                           cpufeat_mask(X86_FEATURE_SSBD));

                /*
                 * Override STIBP to match IBRS.  Guests can safely use STIBP
                 * functionality on non-HT hardware, but can't necesserily protect
                 * themselves from SP2/Spectre/Branch Target Injection if STIBP is
                 * hidden on HT-capable hardware.
                 */
                if ( d & cpufeat_mask(X86_FEATURE_IBRSB) )
                    d |= cpufeat_mask(X86_FEATURE_STIBP);
                else
                    d &= ~cpufeat_mask(X86_FEATURE_STIBP);
            }
            break;

        case 0x80000008:
            /* AMD's IBPB is a subset of IBRS/IBPB. */
            domain_cpuid(currd, 7, 0, &_eax, &_ebx, &_ecx, &_edx);
            if ( _edx & cpufeat_mask(X86_FEATURE_IBRSB) )
                b |= cpufeat_mask(X86_FEATURE_IBPB);
            break;
        }
        goto out;
    }

    cpuid_count(a, c, &a, &b, &c, &d);

    if ( (regs->eax & 0x7fffffff) == 0x00000001 )
    {
        /* Modify Feature Information. */
        if ( !cpu_has_apic )
            __clear_bit(X86_FEATURE_APIC, &d);

        if ( !is_pvh_domain(currd) )
        {
            __clear_bit(X86_FEATURE_PSE, &d);
            __clear_bit(X86_FEATURE_PGE, &d);
            __clear_bit(X86_FEATURE_PSE36, &d);
            __clear_bit(X86_FEATURE_VME, &d);
        }
    }

    switch ( regs->_eax )
    {
    case 0x00000001:
        /* Modify Feature Information. */
        if ( !cpu_has_sep )
            __clear_bit(X86_FEATURE_SEP, &d);
        __clear_bit(X86_FEATURE_DS, &d);
        __clear_bit(X86_FEATURE_ACC, &d);
        __clear_bit(X86_FEATURE_PBE, &d);
        if ( is_pvh_domain(currd) )
            __clear_bit(X86_FEATURE_MTRR, &d);

        __clear_bit(X86_FEATURE_DTES64 % 32, &c);
        __clear_bit(X86_FEATURE_MWAIT % 32, &c);
        __clear_bit(X86_FEATURE_DSCPL % 32, &c);
        __clear_bit(X86_FEATURE_VMXE % 32, &c);
        __clear_bit(X86_FEATURE_SMXE % 32, &c);
        __clear_bit(X86_FEATURE_TM2 % 32, &c);
        if ( is_pv_32bit_domain(currd) )
            __clear_bit(X86_FEATURE_CX16 % 32, &c);
        __clear_bit(X86_FEATURE_XTPR % 32, &c);
        __clear_bit(X86_FEATURE_PDCM % 32, &c);
        __clear_bit(X86_FEATURE_PCID % 32, &c);
        __clear_bit(X86_FEATURE_DCA % 32, &c);
        if ( !cpu_has_xsave )
        {
            __clear_bit(X86_FEATURE_XSAVE % 32, &c);
            __clear_bit(X86_FEATURE_AVX % 32, &c);
        }
        if ( !cpu_has_apic )
           __clear_bit(X86_FEATURE_X2APIC % 32, &c);
        __set_bit(X86_FEATURE_HYPERVISOR % 32, &c);
        break;

    case 0x00000007:
        if ( regs->_ecx == 0 )
        {
            b &= (cpufeat_mask(X86_FEATURE_BMI1) |
                  cpufeat_mask(X86_FEATURE_HLE)  |
                  cpufeat_mask(X86_FEATURE_AVX2) |
                  cpufeat_mask(X86_FEATURE_BMI2) |
                  cpufeat_mask(X86_FEATURE_ERMS) |
                  cpufeat_mask(X86_FEATURE_RTM)  |
                  cpufeat_mask(X86_FEATURE_RDSEED)  |
                  cpufeat_mask(X86_FEATURE_ADX)  |
                  cpufeat_mask(X86_FEATURE_FSGSBASE));

            if ( boot_cpu_has(X86_FEATURE_SC_MSR_PV) )
                d &= cpufeat_mask(X86_FEATURE_IBRSB) |
                     cpufeat_mask(X86_FEATURE_SSBD);
            else
                d = 0;

            /* Override STIBP to match IBRS (see above). */
            if ( d & cpufeat_mask(X86_FEATURE_IBRSB) )
                d |= cpufeat_mask(X86_FEATURE_STIBP);
            else
                d &= ~cpufeat_mask(X86_FEATURE_STIBP);
        }
        else
            b = d = 0;
        a = c = 0;
        break;

    case XSTATE_CPUID:
    xstate:
        if ( !cpu_has_xsave )
            goto unsupported;
        if ( regs->_ecx == 1 )
        {
            a &= XSTATE_FEATURE_XSAVEOPT |
                 XSTATE_FEATURE_XSAVEC |
                 (cpu_has_xgetbv1 ? XSTATE_FEATURE_XGETBV1 : 0) |
                 (cpu_has_xsaves ? XSTATE_FEATURE_XSAVES : 0);
            if ( !cpu_has_xsaves )
                b = c = d = 0;
        }
        break;

    case 0x80000001:
        /* Modify Feature Information. */
        if ( is_pv_32bit_domain(currd) )
        {
            __clear_bit(X86_FEATURE_LM % 32, &d);
            __clear_bit(X86_FEATURE_LAHF_LM % 32, &c);
        }
        if ( is_pv_32bit_domain(currd) &&
             boot_cpu_data.x86_vendor != X86_VENDOR_AMD )
            __clear_bit(X86_FEATURE_SYSCALL % 32, &d);
        __clear_bit(X86_FEATURE_PAGE1GB % 32, &d);
        __clear_bit(X86_FEATURE_RDTSCP % 32, &d);

        __clear_bit(X86_FEATURE_SVM % 32, &c);
        if ( !cpu_has_apic )
           __clear_bit(X86_FEATURE_EXTAPIC % 32, &c);
        __clear_bit(X86_FEATURE_OSVW % 32, &c);
        __clear_bit(X86_FEATURE_IBS % 32, &c);
        __clear_bit(X86_FEATURE_SKINIT % 32, &c);
        __clear_bit(X86_FEATURE_WDT % 32, &c);
        __clear_bit(X86_FEATURE_LWP % 32, &c);
        __clear_bit(X86_FEATURE_NODEID_MSR % 32, &c);
        __clear_bit(X86_FEATURE_TOPOEXT % 32, &c);
        __clear_bit(X86_FEATURE_MWAITX % 32, &c);
        break;

    case 0x80000008:
        /* AMD's IBPB is a subset of IBRS/IBPB. */
        if ( boot_cpu_has(X86_FEATURE_IBRSB) )
            b |= cpufeat_mask(X86_FEATURE_IBPB);
        break;

    case 0x0000000a: /* Architectural Performance Monitor Features (Intel) */
        break;

    case 0x00000005: /* MONITOR/MWAIT */
    case 0x0000000b: /* Extended Topology Enumeration */
    case 0x8000000a: /* SVM revision and features */
    case 0x8000001b: /* Instruction Based Sampling */
    case 0x8000001c: /* Light Weight Profiling */
    case 0x8000001e: /* Extended topology reporting */
    unsupported:
        a = b = c = d = 0;
        break;

    default:
        (void)cpuid_hypervisor_leaves(regs->eax, 0, &a, &b, &c, &d);
        break;
    }

 out:
    /* VPMU may decide to modify some of the leaves */
    vpmu_do_cpuid(regs->eax, &a, &b, &c, &d);

    regs->eax = a;
    regs->ebx = b;
    regs->ecx = c;
    regs->edx = d;
}
