void vmx_get_segment_register(struct vcpu *v, enum x86_segment seg,
                              struct segment_register *reg)
{
    unsigned long attr = 0, sel = 0, limit;

    /*
     * We may get here in the context of dump_execstate(), which may have
     * interrupted context switching between setting "current" and
     * vmx_do_resume() reaching the end of vmx_load_vmcs(). That would make
     * all the VMREADs below fail if we don't bail right away.
     */
    if ( unlikely(!vmx_vmcs_try_enter(v)) )
    {
        static bool_t warned;

        if ( !warned )
        {
            warned = 1;
            printk(XENLOG_WARNING "Segment register inaccessible for d%dv%d\n"
                   "(If you see this outside of debugging activity,"
                   " please report to xen-devel@lists.xenproject.org)\n",
                   v->domain->domain_id, v->vcpu_id);
        }
        memset(reg, 0, sizeof(*reg));
        return;
    }

    switch ( seg )
    {
    case x86_seg_cs:
        __vmread(GUEST_CS_SELECTOR, &sel);
        __vmread(GUEST_CS_LIMIT,    &limit);
        __vmread(GUEST_CS_BASE,     &reg->base);
        __vmread(GUEST_CS_AR_BYTES, &attr);
        break;
    case x86_seg_ds:
        __vmread(GUEST_DS_SELECTOR, &sel);
        __vmread(GUEST_DS_LIMIT,    &limit);
        __vmread(GUEST_DS_BASE,     &reg->base);
        __vmread(GUEST_DS_AR_BYTES, &attr);
        break;
    case x86_seg_es:
        __vmread(GUEST_ES_SELECTOR, &sel);
        __vmread(GUEST_ES_LIMIT,    &limit);
        __vmread(GUEST_ES_BASE,     &reg->base);
        __vmread(GUEST_ES_AR_BYTES, &attr);
        break;
    case x86_seg_fs:
        __vmread(GUEST_FS_SELECTOR, &sel);
        __vmread(GUEST_FS_LIMIT,    &limit);
        __vmread(GUEST_FS_BASE,     &reg->base);
        __vmread(GUEST_FS_AR_BYTES, &attr);
        break;
    case x86_seg_gs:
        __vmread(GUEST_GS_SELECTOR, &sel);
        __vmread(GUEST_GS_LIMIT,    &limit);
        __vmread(GUEST_GS_BASE,     &reg->base);
        __vmread(GUEST_GS_AR_BYTES, &attr);
        break;
    case x86_seg_ss:
        __vmread(GUEST_SS_SELECTOR, &sel);
        __vmread(GUEST_SS_LIMIT,    &limit);
        __vmread(GUEST_SS_BASE,     &reg->base);
        __vmread(GUEST_SS_AR_BYTES, &attr);
        break;
    case x86_seg_tr:
        __vmread(GUEST_TR_SELECTOR, &sel);
        __vmread(GUEST_TR_LIMIT,    &limit);
        __vmread(GUEST_TR_BASE,     &reg->base);
        __vmread(GUEST_TR_AR_BYTES, &attr);
        break;
    case x86_seg_gdtr:
        __vmread(GUEST_GDTR_LIMIT, &limit);
        __vmread(GUEST_GDTR_BASE,  &reg->base);
        break;
    case x86_seg_idtr:
        __vmread(GUEST_IDTR_LIMIT, &limit);
        __vmread(GUEST_IDTR_BASE,  &reg->base);
        break;
    case x86_seg_ldtr:
        __vmread(GUEST_LDTR_SELECTOR, &sel);
        __vmread(GUEST_LDTR_LIMIT,    &limit);
        __vmread(GUEST_LDTR_BASE,     &reg->base);
        __vmread(GUEST_LDTR_AR_BYTES, &attr);
        break;
    default:
        BUG();
        return;
    }

    vmx_vmcs_exit(v);

    reg->sel = sel;
    reg->limit = limit;

    /*
     * Fold VT-x representation into Xen's representation.  The Present bit is
     * unconditionally set to the inverse of unusable.
     */
    reg->attr.bytes =
        (!(attr & (1u << 16)) << 7) | (attr & 0x7f) | ((attr >> 4) & 0xf00);

    /* Adjust for virtual 8086 mode */
    if ( v->arch.hvm_vmx.vmx_realmode && seg <= x86_seg_tr 
         && !(v->arch.hvm_vmx.vm86_segment_mask & (1u << seg)) )
    {
        struct segment_register *sreg = &v->arch.hvm_vmx.vm86_saved_seg[seg];
        if ( seg == x86_seg_tr ) 
            *reg = *sreg;
        else if ( reg->base != sreg->base || seg == x86_seg_ss )
        {
            /* If the guest's reloaded the segment, remember the new version.
             * We can't tell if the guest reloaded the segment with another 
             * one that has the same base.  By default we assume it hasn't,
             * since we don't want to lose big-real-mode segment attributes,
             * but for SS we assume it has: the Ubuntu graphical bootloader
             * does this and gets badly confused if we leave the old SS in 
             * place. */
            reg->attr.bytes = (seg == x86_seg_cs ? rm_cs_attr : rm_ds_attr);
            *sreg = *reg;
        }
        else 
        {
            /* Always give realmode guests a selector that matches the base
             * but keep the attr and limit from before */
            *reg = *sreg;
            reg->sel = reg->base >> 4;
        }
    }
}
